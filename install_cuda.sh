#!/bin/bash
# CUDAå…¼å®¹çš„å®‰è£…è„šæœ¬
# åŸºäºMac M3å®‰è£…è„šæœ¬ï¼Œå¢åŠ äº†CUDAç¯å¢ƒæ”¯æŒ

set -e

echo "============================================================"
echo "ğŸš€ CUDAå…¼å®¹çš„pytracking-pdestrainå®‰è£…è„šæœ¬"
echo "============================================================"

# æ£€æŸ¥å‚æ•°
if [ $# -eq 0 ]; then
    echo "ç”¨æ³•: $0 <condaç¯å¢ƒåç§°>"
    echo "ç¤ºä¾‹: $0 pytracking-cuda"
    exit 1
fi

conda_env_name=$1

echo "ğŸ“‹ å®‰è£…å‚æ•°:"
echo "   Condaç¯å¢ƒ: ${conda_env_name}"
echo "   ç³»ç»Ÿæ¶æ„: $(uname -m)"
echo "   æ“ä½œç³»ç»Ÿ: $(uname -s)"
echo ""

# æ£€æŸ¥condaæ˜¯å¦å¯ç”¨
if command -v conda &> /dev/null; then
    echo "âœ… æ£€æµ‹åˆ°conda: $(conda --version)"
    conda_path=$(command -v conda)
    echo "   Condaè·¯å¾„: ${conda_path}"
else
    echo "âŒ æœªæ£€æµ‹åˆ°condaï¼Œè¯·å…ˆå®‰è£…Anacondaæˆ–Miniconda"
    exit 1
fi

# åˆå§‹åŒ–conda
echo ""
echo "****************** åˆå§‹åŒ–condaç¯å¢ƒ ******************"
eval "$(conda shell.bash hook)"
conda info --envs

echo ""
echo "****************** åˆ›å»ºcondaç¯å¢ƒ ${conda_env_name} ******************"
if conda env list | grep -q "^${conda_env_name} "; then
    echo "âš ï¸  ç¯å¢ƒ ${conda_env_name} å·²å­˜åœ¨ï¼Œå°†é‡æ–°åˆ›å»º"
    conda env remove -n ${conda_env_name} -y
fi

# åˆ›å»ºæ–°çš„condaç¯å¢ƒ
conda create -n ${conda_env_name} python=3.9 -y
echo "âœ… å·²åˆ›å»ºcondaç¯å¢ƒ ${conda_env_name}"

echo ""
echo "****************** æ¿€æ´»ç¯å¢ƒå¹¶å®‰è£…ä¾èµ– ******************"
conda activate ${conda_env_name}

# å®‰è£…PyTorch CUDAç‰ˆæœ¬
echo "ğŸ“¦ å®‰è£…PyTorch CUDAç‰ˆæœ¬..."
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y

# å®‰è£…å…¶ä»–æ ¸å¿ƒä¾èµ–
echo "ğŸ“¦ å®‰è£…å…¶ä»–æ ¸å¿ƒä¾èµ–..."
conda install -c conda-forge opencv pillow numpy scipy matplotlib tqdm -y

# å®‰è£…å¯é€‰ä¾èµ–
echo "ğŸ“¦ å®‰è£…å¯é€‰ä¾èµ–..."
conda install -c conda-forge tensorboard visdom -y

# å®‰è£…timm
echo "ğŸ“¦ å®‰è£…timm..."
pip install timm

# å®‰è£…å…¶ä»–PythonåŒ…
echo "ğŸ“¦ å®‰è£…å…¶ä»–PythonåŒ…..."
pip install -r requirements.txt

echo ""
echo "****************** éªŒè¯å®‰è£… ******************"
echo "ğŸ” æ£€æŸ¥PyTorch CUDAæ”¯æŒ..."
python -c "
import torch
print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')
print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDAç‰ˆæœ¬: {torch.version.cuda}')
    print(f'GPUæ•°é‡: {torch.cuda.device_count()}')
    for i in range(torch.cuda.device_count()):
        print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
else:
    print('âŒ CUDAä¸å¯ç”¨')
"

echo ""
echo "****************** å®‰è£…å®Œæˆ ******************"
echo "âœ… ç¯å¢ƒ ${conda_env_name} å®‰è£…å®Œæˆï¼"
echo ""
echo "ğŸ“‹ ä½¿ç”¨æ–¹æ³•:"
echo "1. æ¿€æ´»ç¯å¢ƒ: conda activate ${conda_env_name}"
echo "2. è¿è¡ŒCUDAè®­ç»ƒ: python train_dimp_pdes_cuda.py --model dimp18"
echo "3. æ£€æŸ¥GPUçŠ¶æ€: nvidia-smi"
echo ""
echo "ğŸ”§ æ•…éšœæ’é™¤:"
echo "- å¦‚æœCUDAä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥NVIDIAé©±åŠ¨å®‰è£…"
echo "- ç¡®ä¿PyTorchç‰ˆæœ¬ä¸CUDAç‰ˆæœ¬å…¼å®¹"
echo "- æ£€æŸ¥GPUå†…å­˜æ˜¯å¦è¶³å¤Ÿ"
echo ""
echo "ğŸ‰ å®‰è£…å®Œæˆï¼"
