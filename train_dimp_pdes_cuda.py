#!/usr/bin/env python3
"""
CUDAå…¼å®¹çš„DiMPè¡Œäººè·Ÿè¸ªè®­ç»ƒå¯åŠ¨è„šæœ¬
åŸºäºMac M3å…¼å®¹ç‰ˆæœ¬ï¼Œå¢åŠ äº†CUDAç¯å¢ƒæ”¯æŒ
"""

import argparse
import os
import sys
import torch

def check_cuda_environment():
    """æ£€æŸ¥CUDAç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥CUDAç¯å¢ƒ...")
    
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥CUDAå®‰è£…")
        return False
    
    print(f"âœ… CUDAå¯ç”¨ï¼Œç‰ˆæœ¬: {torch.version.cuda}")
    print(f"âœ… GPUæ•°é‡: {torch.cuda.device_count()}")
    
    for i in range(torch.cuda.device_count()):
        gpu_name = torch.cuda.get_device_name(i)
        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
        print(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
    
    return True

def main():
    parser = argparse.ArgumentParser(description='CUDAå…¼å®¹çš„DiMPè¡Œäººè·Ÿè¸ªè®­ç»ƒ')
    parser.add_argument('--model', choices=['dimp18', 'dimp50'], default='dimp18',
                       help='æ¨¡å‹å˜ä½“ (é»˜è®¤: dimp18)')
    parser.add_argument('--config', default=None,
                       help='è‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume', action='store_true',
                       help='ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ')
    parser.add_argument('--debug', action='store_true',
                       help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸš€ DiMP CUDAå…¼å®¹è®­ç»ƒå¯åŠ¨")
    print("=" * 60)
    print(f"æ¨¡å‹: {args.model}")
    print(f"é…ç½®: {args.config or f'{args.model}_pdes_cuda'}")
    print(f"æ¢å¤è®­ç»ƒ: {'æ˜¯' if args.resume else 'å¦'}")
    print(f"è°ƒè¯•æ¨¡å¼: {'æ˜¯' if args.debug else 'å¦'}")
    print("=" * 60)
    
    # æ£€æŸ¥CUDAç¯å¢ƒ
    if not check_cuda_environment():
        sys.exit(1)
    
    # æ£€æŸ¥ç¯å¢ƒè®¾ç½®
    print("\nğŸ” æ£€æŸ¥ç¯å¢ƒè®¾ç½®...")
    pedestrain_dir = os.environ.get('PEDESTRAIN_DIR', '/Users/xingqiangchen/TASK/pytracking-pdestrain/pedestrain')
    if os.path.exists(pedestrain_dir):
        print(f"   âœ… è¡Œäººæ•°æ®é›†è·¯å¾„: {pedestrain_dir}")
    else:
        print(f"   âš ï¸  è¡Œäººæ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {pedestrain_dir}")
    
    # è®¾ç½®CUDAè®¾å¤‡
    if torch.cuda.is_available():
        device = torch.device('cuda:0')
        print(f"   âœ… ä½¿ç”¨CUDAè®¾å¤‡: {device}")
        print(f"   âœ… å½“å‰GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("   âŒ CUDAä¸å¯ç”¨")
        sys.exit(1)
    
    # å¯åŠ¨è®­ç»ƒ
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ {args.model}_pdes_cuda...")
    
    try:
        # å¯¼å…¥è®­ç»ƒæ¨¡å—
        from ltr.run_training import run_training
        
        # ç¡®å®šè®­ç»ƒé…ç½®
        if args.config:
            train_module = 'dimp'
            train_name = args.config
        else:
            train_module = 'dimp'
            train_name = f'{args.model}_pdes_cuda'
        
        # è¿è¡Œè®­ç»ƒ
        run_training(train_module, train_name)
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ è®­ç»ƒé”™è¯¯: {e}")
        sys.exit(1)

if __name__ == '__main__':
    main()
