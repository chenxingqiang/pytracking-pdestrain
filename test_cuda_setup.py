#!/usr/bin/env python3
"""
CUDAå…¼å®¹æ€§æµ‹è¯•è„šæœ¬
éªŒè¯CUDAç¯å¢ƒã€æ•°æ®é›†åŠ è½½å’Œæ¨¡å‹å…¼å®¹æ€§
"""

import os
import sys
import torch
import numpy as np

def test_cuda_environment():
    """æµ‹è¯•CUDAç¯å¢ƒ"""
    print("ğŸ” æµ‹è¯•CUDAç¯å¢ƒ...")
    
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨")
        return False
    
    print(f"âœ… CUDAå¯ç”¨ï¼Œç‰ˆæœ¬: {torch.version.cuda}")
    print(f"âœ… GPUæ•°é‡: {torch.cuda.device_count()}")
    
    # æµ‹è¯•GPUå†…å­˜
    for i in range(torch.cuda.device_count()):
        props = torch.cuda.get_device_properties(i)
        total_memory = props.total_memory / 1024**3
        print(f"   GPU {i}: {props.name} ({total_memory:.1f} GB)")
        
        # æµ‹è¯•GPUè®¡ç®—
        torch.cuda.set_device(i)
        x = torch.randn(1000, 1000).cuda()
        y = torch.randn(1000, 1000).cuda()
        z = torch.mm(x, y)
        print(f"   âœ… GPU {i} è®¡ç®—æµ‹è¯•é€šè¿‡")
    
    return True

def test_dataset_loading():
    """æµ‹è¯•æ•°æ®é›†åŠ è½½"""
    print("\nğŸ” æµ‹è¯•æ•°æ®é›†åŠ è½½...")
    
    try:
        from ltr.dataset import PdesDataset
        from ltr.data import sampler
        
        # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
        pedestrain_dir = os.environ.get('PEDESTRAIN_DIR', '/Users/xingqiangchen/TASK/pytracking-pdestrain/pedestrain')
        if not os.path.exists(pedestrain_dir):
            print(f"   âš ï¸  è¡Œäººæ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {pedestrain_dir}")
            return False
        
        print(f"   âœ… è¡Œäººæ•°æ®é›†è·¯å¾„: {pedestrain_dir}")
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = PdesDataset(root=pedestrain_dir)
        print(f"   âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œåºåˆ—æ•°é‡: {len(dataset.sequence_list)}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        if len(dataset.sequence_list) > 0:
            seq_info = dataset.get_sequence_info(0)
            print(f"   âœ… åºåˆ—ä¿¡æ¯è·å–æˆåŠŸ: {seq_info}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_compatibility():
    """æµ‹è¯•æ¨¡å‹å…¼å®¹æ€§"""
    print("\nğŸ” æµ‹è¯•æ¨¡å‹å…¼å®¹æ€§...")
    
    try:
        # æµ‹è¯•RoIæ± åŒ–
        try:
            from ltr.external.PreciseRoIPooling.pytorch.prroi_pool import PrRoIPool2D
            print("   âœ… PreciseRoIPoolingå¯¼å…¥æˆåŠŸ")
        except ImportError:
            from ltr.models.layers.roi_pool_mac import PrRoIPool2D
            print("   âœ… Macå…¼å®¹RoIæ± åŒ–å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•åŸºæœ¬æ¨¡å‹ç»„ä»¶
        roi_pool = PrRoIPool2D(3, 3, 1.0/16.0)
        features = torch.randn(1, 256, 32, 32)
        rois = torch.tensor([[0, 10, 10, 20, 20]], dtype=torch.float32)
        
        if torch.cuda.is_available():
            roi_pool = roi_pool.cuda()
            features = features.cuda()
            rois = rois.cuda()
        
        output = roi_pool(features, rois)
        print(f"   âœ… RoIæ± åŒ–æµ‹è¯•æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ æ¨¡å‹å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_training_config():
    """æµ‹è¯•è®­ç»ƒé…ç½®"""
    print("\nğŸ” æµ‹è¯•è®­ç»ƒé…ç½®...")
    
    try:
        # æµ‹è¯•CUDAè®­ç»ƒé…ç½®
        from ltr.train_settings.dimp import dimp18_pdes_cuda, dimp50_pdes_cuda
        
        print("   âœ… CUDAè®­ç»ƒé…ç½®å¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºæ¨¡æ‹Ÿè®¾ç½®å¯¹è±¡
        class MockSettings:
            def __init__(self):
                self.batch_size = 8
                self.num_workers = 0
                self.multi_gpu = False
        
        settings = MockSettings()
        
        # æµ‹è¯•é…ç½®å‡½æ•°
        dimp18_pdes_cuda.run(settings)
        print(f"   âœ… DiMP18 CUDAé…ç½®æµ‹è¯•æˆåŠŸ")
        print(f"      æ‰¹æ¬¡å¤§å°: {settings.batch_size}")
        print(f"      å·¥ä½œå™¨æ•°é‡: {settings.num_workers}")
        print(f"      å¤šGPU: {settings.multi_gpu}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ è®­ç»ƒé…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ CUDAå…¼å®¹æ€§æµ‹è¯•")
    print("=" * 60)
    
    tests = [
        ("CUDAç¯å¢ƒ", test_cuda_environment),
        ("æ•°æ®é›†åŠ è½½", test_dataset_loading),
        ("æ¨¡å‹å…¼å®¹æ€§", test_model_compatibility),
        ("è®­ç»ƒé…ç½®", test_training_config),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"   âŒ {test_name}æµ‹è¯•å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“‹ æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:15} : {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼CUDAç¯å¢ƒé…ç½®æˆåŠŸï¼")
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œè®­ç»ƒ: python train_dimp_pdes_cuda.py --model dimp18")
        print("2. æ£€æŸ¥GPUçŠ¶æ€: nvidia-smi")
        print("3. ç›‘æ§è®­ç»ƒè¿›åº¦")
    else:
        print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("- æ£€æŸ¥CUDAé©±åŠ¨å®‰è£…")
        print("- éªŒè¯PyTorch CUDAç‰ˆæœ¬")
        print("- ç¡®è®¤æ•°æ®é›†è·¯å¾„æ­£ç¡®")
    
    return passed == total

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
